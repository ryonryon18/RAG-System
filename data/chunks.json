[
  {
    "source": "how_to_use_rag.md",
    "text": "# RAGの仕組み RAG（Retrieval-Augmented Generation）は、外部文書から情報を検索し、言語モデルの応答に組み込む構造です。 主な処理の流れは以下の通りです： ## 1. チャンク分割 ドキュメントは意味の通る長さに分割され（例：300トークン）、各チャンクが検索対象になります。 ## 2. ベクトル化（Embedding） 分割されたチャンクをベクトルに変換します。ベクトルとは文書の意味を数値化したもので、OpenAIやSentenceTransformersなどのモデルが使われます。 ## 3. クエリのEmbeddingと検索 ユーザーの質問も同様にEmbeddingされ、チャンクと比較して意味が近いものをRetrieverが選びます（例：Top-k、MMR、Hybrid）。 ## 4. 生成（Generation） 選ばれたチャンクをLLMに与えて、文脈に沿った自然な回答を生成します。 --- この4ステップにより、RAGはLLMに動的かつ信頼性のある知識を与えることができます。"
  },
  {
    "source": "medical_guidelines.md",
    "text": "# 医療分野におけるRAGの活用 RAGは医療分野でのナレッジ検索・説明生成にも応用されています。 ## 利用例1：ガイドラインの解釈支援 厚労省や学会が発行する医療ガイドラインは専門的で難解ですが、RAGを使うことで「◯◯の患者に対する治療方針は？」といった質問に対し、根拠付きで平易に説明することができます。 ## 利用例2：院内ドキュメント検索 電子カルテ、看護記録、標準手順書（SOP）などから必要情報を素早く抽出。既存のFAQでは対応できない文脈依存の質問にも柔軟に応答可能です。 ## 利用例3：患者向け説明文の自動生成 医師が説明に使う文書や、患者への案内を生成する際に、医学用語をわかりやすく置き換えて提供できます。医療コミュニケーションの質向上に寄与します。 --- 医療は正確性と文脈理解が求められる分野であり、RAGはその両方を補完する手段として注目されています。"
  },
  {
    "source": "what_is_rag.md",
    "text": "# RAGとは何か？ RAG（Retrieval-Augmented Generation）は、外部知識を検索し、大規模言語モデル（LLM）の応答に取り入れる仕組みです。 従来のLLMは、事前に学習された情報しか扱えませんでしたが、RAGでは動的に外部文書を検索して回答に利用するため、最新かつ正確な情報を提供できます。 主に以下のステップで構成されます： 1. クエリ（質問）をEmbeddingに変換 2. 関連する文書チャンクをRetrieverで検索 3. 検索結果をもとにLLMが回答を生成 これにより、LLMの弱点だった「事実誤認」や「知識の古さ」を補うことができます。"
  }
]